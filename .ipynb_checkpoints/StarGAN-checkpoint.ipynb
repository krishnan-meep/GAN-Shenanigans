{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import grad as torch_grad\n",
    "from models.cycgan import Star_Generator, Star_Patch_Discriminator\n",
    "from utils import load_data\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathnames = [\"/content/drive/My Drive/Datasets/vanGogh2Phots/trainA\", \"/content/drive/My Drive/Datasets/vanGogh2Phots/trainB\",\n",
    "             \"/content/drive/My Drive/Datasets/Fruits\", \"/content/drive/My Drive/Datasets/Ukiyo_e\",\n",
    "             \"/content/drive/My Drive/Datasets/SketchPaints/RandPaintings\"]\n",
    "no_of_domains = len(pathnames)\n",
    "x_train = np.array([])\n",
    "y_train = []\n",
    "\n",
    "def onehotencode(length, index):\n",
    "    encoding = np.zeros(length, dtype = np.float32)\n",
    "    encoding[index] = 1\n",
    "    return encoding\n",
    "\n",
    "for i, path in enumerate(pathnames):\n",
    "    print(\"Loading images from\", path)\n",
    "    data = load_data(path, image_size = (128,128), block_size = 500)\n",
    "    data = (data/255)*2 - 1\n",
    "    y_train = y_train + [onehotencode(no_of_domains, i) for _ in range(len(data))]\n",
    "    x_train = np.vstack([x_train, data]) if x_train.size else data\n",
    "\n",
    "x_train = torch.Tensor(x_train)\n",
    "y_train = torch.Tensor(np.array(y_train))\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_train.max(), x_train.min(), y_train.max(), y_train.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id = np.random.choice(len(x_train), size = 10)\n",
    "data = x_train[batch_id]\n",
    "\n",
    "print(\"data\")\n",
    "print(data.shape)\n",
    "print(data.max(), data.min())\n",
    "img = np.transpose(data[0], (1, 2, 0))\n",
    "plt.imshow((img+1)/2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientPenalty(discriminator_model, real_data, generated_data, gp_weight = 10):\n",
    "    batch_size = real_data.size()[0]\n",
    "\n",
    "    # Calculate interpolation\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1)\n",
    "    alpha = alpha.expand_as(real_data)\n",
    "    if torch.cuda.is_available():\n",
    "        alpha = alpha.cuda()\n",
    "\n",
    "    interpolated = alpha * real_data + (1 - alpha) * generated_data\n",
    "    interpolated = Variable(interpolated, requires_grad=True)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        interpolated = interpolated.cuda()\n",
    "\n",
    "    # Calculate probability of interpolated examples\n",
    "    prob_interpolated, _ = discriminator_model(interpolated)\n",
    "\n",
    "    # Calculate gradients of probabilities with respect to examples\n",
    "    gradients = torch_grad(outputs=prob_interpolated, inputs=interpolated,\n",
    "                           grad_outputs=torch.ones(prob_interpolated.size()).cuda() if torch.cuda.is_available() else torch.ones(\n",
    "                           prob_interpolated.size()),\n",
    "                           create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    # Gradients have shape (batch_size, num_channels, img_width, img_height),\n",
    "    # so flatten to easily take norm per example in batch\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "\n",
    "    # Derivatives of the gradient close to 0 can cause problems because of\n",
    "    # the square root, so manually calculate norm and add epsilon\n",
    "    gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
    "\n",
    "    # Return gradient penalty\n",
    "    return gp_weight * ((gradients_norm - 1) ** 2).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "G = Star_Generator(cond_length = no_of_domains).to(device)\n",
    "D = Star_Patch_Discriminator(img_size = (128,128), in_channels = 3, cond_length = no_of_domains).to(device)\n",
    "\n",
    "for m in G.modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear, nn.ConvTranspose2d)):\n",
    "        nn.init.kaiming_normal(m.weight)\n",
    "\n",
    "for m in D.modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear, nn.ConvTranspose2d)):\n",
    "        nn.init.kaiming_normal(m.weight)\n",
    " \n",
    "#Optimizers\n",
    "optimizerD = optim.Adam(D.parameters(), lr = 0.0002, betas = (0.0, 0.9))\n",
    "optimizerG = optim.Adam(G.parameters(), lr = 0.0002, betas = (0.0, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "_lambda = 10\n",
    "batch_size = 32\n",
    "cls_criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(len(x_train)//batch_size):\n",
    "\n",
    "        #Dealing with the discriminators################################\n",
    "        D.zero_grad()\n",
    "\n",
    "        batch_id = np.random.choice(len(x_train), size = batch_size)\n",
    "        data = x_train[batch_id]\n",
    "        targets = y_train[batch_id].to(device)\n",
    "\n",
    "        real_images = data.to(device)\n",
    "        #Make a bunch of fake labels to translate the images into\n",
    "        fake_targets = np.array([onehotencode(no_of_domains, i) \n",
    "                                 for i in np.random.randint(0, no_of_domains, size = batch_size)])\n",
    "        fake_targets = torch.Tensor(fake_targets).to(device)\n",
    "        \n",
    "        output, pred_cls = D(real_images)\n",
    "        output = output.view(-1)\n",
    "        errD_real = -torch.mean(output) + torch.mean(cls_criterion(F.softmax(pred_cls, dim = 1), fake_targets))\n",
    "\n",
    "        fake_images = G(real_images, fake_targets)\n",
    "        \n",
    "        output, pred_cls = D(fake_images.detach())\n",
    "        output = output.view(-1)\n",
    "        errD_fake = torch.mean(output) + torch.mean(cls_criterion(F.softmax(pred_cls, dim = 1), fake_targets))\n",
    "\n",
    "        GP = GradientPenalty(D, real_images, fake_images, gp_weight = 10)\n",
    "        \n",
    "        errD = errD_fake + errD_real + GP\n",
    "        errD.backward()        \n",
    "\n",
    "        optimizerD.step()\n",
    "\n",
    "        #Dealing with the generators###################################\n",
    "        G.zero_grad()\n",
    "        \n",
    "        output, pred_cls = D(fake_images)\n",
    "        output = output.view(-1)\n",
    "        \n",
    "        errG = -torch.mean(output) + torch.mean(cls_criterion(F.softmax(pred_cls, dim = 1), fake_targets))\n",
    "        \n",
    "        cycled_images = G(fake_images, targets)\n",
    "        \n",
    "        errG_cyc = torch.mean(torch.abs(cycled_images - real_images))\n",
    "        errG_cyc *= _lambda\n",
    "\n",
    "        id_images = G(real_images, targets)\n",
    "        errG_id = torch.mean(torch.abs(id_images - real_images))\n",
    "        errG_id *= 0.1*_lambda\n",
    "\n",
    "        errG = errG + errG_cyc + errG_id\n",
    "        errG.backward()\n",
    "\n",
    "        optimizerG.step()\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print(\"Epoch %i Step %i --> Disc_Loss : %f   Gen_Loss : %f\" % (epoch, i, errD, errG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./saved_models/\"\n",
    "torch.save(G.state_dict(), path + \"stargan_G.pth\")\n",
    "torch.save(D.state_dict(), path + \"stargan_D.pth\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = np.random.choice(len(x_train), size = 10)\n",
    "data_x = x_train[batch_idx]\n",
    "\n",
    "print(\"Actual images\")\n",
    "\n",
    "f, a = plt.subplots(1, 10, figsize=(20, 20))\n",
    "for i in range(10):\n",
    "  img = data_x[i]\n",
    "  img = np.transpose(img, (1, 2, 0))\n",
    "  img = (img+1)/2\n",
    "  a[i].imshow(img)\n",
    "  a[i].axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "with torch.no_grad():\n",
    "  real_images = torch.Tensor(data_x).to(device)\n",
    "  fake_targets = np.array([onehotencode(no_of_domains, i) \n",
    "                           for i in np.random.randint(0, no_of_domains, size = 10)])\n",
    "  fake_targets = torch.Tensor(fake_targets).to(device)\n",
    "  fake_images = G(real_images, fake_targets)\n",
    "\n",
    "print(\"Translated images\")\n",
    "\n",
    "f, a = plt.subplots(1, 10, figsize=(30, 30))\n",
    "for i in range(10):\n",
    "  img = fake_images[i].cpu()\n",
    "  img = np.transpose(img, (1, 2, 0))\n",
    "  img = (img+1)/2\n",
    "  a[i].imshow(img)\n",
    "  a[i].axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Domain translations: \", fake_targets)\n",
    "print(pathnames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
