{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolutionary GAN\n",
    "\n",
    "Based on [this paper](https://arxiv.org/abs/1803.00657) on using an evolutionary setup for the generators, mutating each child according to a different loss function. The generators in this notebook currently only reproduces from a single generator parent but it can be extended to work with multiple parents. [The official repo](https://github.com/WANG-Chaoyue/EvolutionaryGAN-pytorch) was referred to figure out the gradient calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, num_workers=2, shuffle = True)\n",
    "\n",
    "data_loader = iter(trainloader)\n",
    "(data, target) = next(data_loader)\n",
    "\n",
    "print(data.shape)\n",
    "print(data.max(), data.min())\n",
    "img = np.transpose(data[0], (1, 2, 0))\n",
    "plt.imshow((img+1)/2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Basic_Gen(nn.Module):\n",
    "  def __init__(self, image_size = (32, 32), noise_dim = 128):\n",
    "    super(Basic_Gen, self).__init__()\n",
    "    self.h, self.w = image_size[0]//8, image_size[1]//8\n",
    "    self.Proj = nn.Linear(noise_dim, 256*self.h*self.w)\n",
    "    self.C1 = nn.Conv2d(256, 128, 3, 1, 1)\n",
    "    self.C2 = nn.Conv2d(128, 64, 3, 1, 1)\n",
    "    self.C3 = nn.Conv2d(64, 32, 3, 1, 1)\n",
    "    self.C4 = nn.Conv2d(32, 3, 3, 1, 1)\n",
    "\n",
    "    self.B0 = nn.BatchNorm2d(256)\n",
    "    self.B1 = nn.BatchNorm2d(128)\n",
    "    self.B2 = nn.BatchNorm2d(64)\n",
    "    self.B3 = nn.BatchNorm2d(32)\n",
    "\n",
    "    self.C1.weight.data.normal_(0.0, 0.02)\n",
    "    self.C2.weight.data.normal_(0.0, 0.02)\n",
    "    self.C3.weight.data.normal_(0.0, 0.02)\n",
    "    self.C4.weight.data.normal_(0.0, 0.02)\n",
    "\n",
    "  def forward(self, z):\n",
    "    x = self.Proj(z)\n",
    "    x = x.view(-1, 256, self.h, self.w)\n",
    "    x = F.leaky_relu(self.B0(x))\n",
    "    x = F.leaky_relu(self.B1(self.C1(x)))\n",
    "    x = F.interpolate(x, scale_factor = 2)\n",
    "    x = F.leaky_relu(self.B2(self.C2(x)))\n",
    "    x = F.interpolate(x, scale_factor = 2)\n",
    "    x = F.leaky_relu(self.B3(self.C3(x)))\n",
    "    x = F.interpolate(x, scale_factor = 2)\n",
    "    x = torch.tanh(self.C4(x))\n",
    "    return x\n",
    "\n",
    "class Basic_Disc(nn.Module):\n",
    "  def __init__(self, image_size = (32, 32)):\n",
    "    super(Basic_Disc, self).__init__()\n",
    "    self.h, self.w = image_size[0]//8, image_size[1]//8\n",
    "    self.C1 = nn.Conv2d(3, 64, 4, 2, 1)\n",
    "    self.C2 = nn.Conv2d(64, 128, 4, 2, 1)\n",
    "    self.C3 = nn.Conv2d(128, 256, 4, 2, 1)\n",
    "\n",
    "    self.C1.weight.data.normal_(0.0, 0.02)\n",
    "    self.C2.weight.data.normal_(0.0, 0.02)\n",
    "    self.C3.weight.data.normal_(0.0, 0.02)\n",
    "    self.C1 = nn.utils.spectral_norm(self.C1)\n",
    "    self.C2 = nn.utils.spectral_norm(self.C2)\n",
    "    self.C3 = nn.utils.spectral_norm(self.C3)\n",
    "\n",
    "    self.D = nn.Linear(256*self.h*self.w, 1)\n",
    "    self.D = nn.utils.spectral_norm(self.D)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.leaky_relu(self.C1(x))\n",
    "    x = F.leaky_relu(self.C2(x))\n",
    "    x = F.leaky_relu(self.C3(x))\n",
    "    x = x.view(-1, 256*self.h*self.w)\n",
    "    x = self.D(x)\n",
    "    return x\n",
    "\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def loss_func(index, output):\n",
    "  if i == 0:\n",
    "    label = torch.zeros(b_size, 1).to(device)\n",
    "    return -0.5*bce_loss(output, label)\n",
    "  elif i == 1:\n",
    "    label = torch.ones(b_size, 1).to(device)\n",
    "    return 0.5*bce_loss(output, label)\n",
    "  else:\n",
    "    return torch.mean((output - 1)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "noise_dim = 128\n",
    "netG = Basic_Gen(image_size = (32,32), noise_dim = noise_dim).to(device)\n",
    "netD = Basic_Disc(image_size = (32, 32)).to(device)\n",
    "\n",
    "child_count = 3\n",
    "\n",
    "child_Gs = [Basic_Gen(image_size = (32,32), noise_dim = noise_dim).to(device) for _ in range(child_count)]\n",
    "child_opts = [optim.Adam(x.parameters(), lr = 0.0002, betas = (0.5, 0.999)) for x in child_Gs]\n",
    "\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    netG = nn.DataParallel(netG, list(range(torch.cuda.device_count())))\n",
    "    netD = nn.DataParallel(netD, list(range(torch.cuda.device_count())))\n",
    "\n",
    "#Two Timescale Update Rule\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "disc_steps = 2\n",
    "\n",
    "path = \"./saved_models/\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (data, target) in enumerate(trainloader):\n",
    "\n",
    "        #Dealing with the discriminator################################\n",
    "        #Specify number of disc updates above##############\n",
    "        for k in range(disc_steps):\n",
    "            netD.zero_grad()\n",
    "        \n",
    "            b_size = data.size(0)//disc_steps\n",
    "            real_images = data[k*b_size:(k+1)*b_size].to(device)\n",
    "            real_label, fake_label = torch.ones(b_size, 1).to(device), torch.zeros(b_size, 1).to(device)\n",
    "\n",
    "            output = netD(real_images).view(b_size, -1)\n",
    "            errD_real = bce_loss(output, real_label)\n",
    "\n",
    "            noise = torch.randn(b_size, noise_dim, device = device)\n",
    "            fake = netG(noise)\n",
    "\n",
    "            output = netD(fake.detach()).view(b_size, -1)\n",
    "            errD_fake = bce_loss(output, fake_label)\n",
    "\n",
    "            errD = errD_fake + errD_real\n",
    "            errD.backward()\n",
    "            optimizerD.step()\n",
    "            \n",
    "        #Dealing with the generator###################################\n",
    "        netG.zero_grad()\n",
    "        for g, o in zip(child_Gs, child_opts):\n",
    "          g.zero_grad()\n",
    "          g.load_state_dict(netG.state_dict())\n",
    "          o.load_state_dict(optimizerG.state_dict())\n",
    "        F_scores, errGs = [], []\n",
    "\n",
    "        for k in range(child_count):\n",
    "            #Mutate the child\n",
    "            netD.zero_grad()\n",
    "            noise = torch.randn(b_size, noise_dim, device = device)\n",
    "            fake = child_Gs[k](noise)\n",
    "            fake_output = netD(fake).view(b_size, -1)\n",
    "\n",
    "            errG = loss_func(k, fake_output)\n",
    "            errGs.append(errG.data.cpu().numpy().item())\n",
    "            errG.backward()\n",
    "            child_opts[k].step()\n",
    "\n",
    "            #Evaluate post mutation\n",
    "            netD.zero_grad()\n",
    "            noise = torch.randn(b_size, noise_dim, device = device)\n",
    "            real_output = netD(real_images).view(b_size, -1)\n",
    "            fake_output = netD(child_Gs[k](noise)).view(b_size, -1)\n",
    "\n",
    "            Fq = torch.sigmoid(fake_output).data.mean().cpu().numpy()\n",
    "\n",
    "            div_loss = bce_loss(real_output, real_label) + bce_loss(fake_output, fake_label)\n",
    "            gradients = torch.autograd.grad(outputs=div_loss, inputs=netD.parameters(),\n",
    "                                            grad_outputs=torch.ones(div_loss.size()).to(device),\n",
    "                                            create_graph=True, retain_graph=True, only_inputs=True)\n",
    "            with torch.no_grad():\n",
    "                for p, grad in enumerate(gradients):\n",
    "                    grad = grad.view(-1)\n",
    "                    allgrad = grad if p == 0 else torch.cat([allgrad,grad]) \n",
    "\n",
    "            Fd = -torch.log(torch.norm(allgrad)).data.cpu().numpy()\n",
    "            F_scores.append(Fq + 0.001*Fd)\n",
    "\n",
    "        #Figure out best child\n",
    "        best_index = np.argsort(F_scores)[-1]\n",
    "        netG.load_state_dict(child_Gs[best_index].state_dict())\n",
    "        optimizerG.load_state_dict(child_opts[best_index].state_dict())\n",
    "\n",
    "        if i%100 == 0:\n",
    "            print(epoch, epochs, i, len(trainloader), \"D: \", errD.item(), \"Gs: \", errGs, F_scores, best_index)\n",
    "            \n",
    "    if epoch%2 == 0:\n",
    "        !nvidia-smi;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(40, noise_dim, device = device)\n",
    "\n",
    "with torch.no_grad():\n",
    "  fake = []\n",
    "  for i in range(7):\n",
    "    f = netG(noise[i*10:(i+1)*10])\n",
    "    fake.append(f.cpu())\n",
    "  fake = torch.cat(fake)\n",
    "\n",
    "print(fake.shape)\n",
    "grid = torchvision.utils.make_grid(fake, nrow = 10, padding = 1, pad_value = 0.15)\n",
    "f = plt.figure(figsize=(15,15))\n",
    "plt.imshow((grid.permute(1, 2, 0)+1)/2)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
