{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GauGAN (Without Encoder)\n",
    "\n",
    "Generator with SPADE Resblocks (modulated by binary thresholded versions of images), Patch Discriminator conditioned on binary versions of images, Hinge Loss. SpecNorm in both generator and discriminator.\n",
    "\n",
    "GauGAN transforms a noise vector modulated by a segmented image into a filled real version of that segmented image. Modulation's called Spatially Adpative Normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "vpQFOinkvp_y",
    "outputId": "1ce0b5c0-b079-448b-e6cb-21e438c821f7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from models.gaugan import SPADE_Generator, Patch_Discriminator\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QAe5XmxwGx2"
   },
   "outputs": [],
   "source": [
    "def load_data(path, image_size, block_size = None, thresholded = False):\n",
    "  x_train = []\n",
    "  files = os.listdir(path)\n",
    "  #shuffle(files)\n",
    "  if block_size is None or block_size > len(files):\n",
    "    block_size = len(files)\n",
    "\n",
    "  for i,file in enumerate(files):\n",
    "    img = cv2.imread(path+\"/\"+file)\n",
    "    img = cv2.resize(img, (image_size[1], image_size[0]))\n",
    "\n",
    "    if thresholded:\n",
    "      img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "      img = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "      ret, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "      img = img.reshape(image_size[0], image_size[1], 1)\n",
    "    else:\n",
    "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "      \n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    img = np.float32(img)\n",
    "    x_train.append(img)\n",
    "    print(i,\"/\",block_size)\n",
    "\n",
    "    if i >= block_size - 1:\n",
    "      break\n",
    "\n",
    "  return np.array(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "i_If18IjvvYx",
    "outputId": "08677a84-2eda-404b-fc50-72cb449594ca"
   },
   "outputs": [],
   "source": [
    "x_train = load_data(path=\"/content/drive/My Drive/Datasets/vanGogh2Phots/trainB\", image_size = (128,128))\n",
    "y_train = load_data(path=\"/content/drive/My Drive/Datasets/vanGogh2Phots/trainB\", image_size = (128,128), thresholded = True)\n",
    "\n",
    "x_train = (x_train/255)*2 - 1\n",
    "print(x_train.max(), x_train.min())\n",
    "print(x_train.shape)\n",
    "\n",
    "y_train = (y_train/255)*2 - 1\n",
    "print(y_train.max(), y_train.min())\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "colab_type": "code",
    "id": "yJq5O0OAwYzn",
    "outputId": "ea0593e2-ff7a-46f5-964a-c3365aa65453"
   },
   "outputs": [],
   "source": [
    "img = np.transpose(x_train[10], (1, 2, 0))\n",
    "plt.imshow((img+1)/2)\n",
    "plt.show()\n",
    "img = np.transpose(y_train[10], (1, 2, 0))\n",
    "plt.imshow((img.reshape(128,128)+1)/2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FfLN-l8Qv7CZ"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "noise_dim = 128\n",
    "netG = SPADE_Generator(image_size = (128,128), noise_dim = noise_dim, seg_channels = 1, specnorm = True).to(device)\n",
    "netD = Patch_Discriminator(image_size = (128,128), in_channels = 4).to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    netG = nn.DataParallel(netG, list(range(torch.cuda.device_count())))\n",
    "    netD = nn.DataParallel(netD, list(range(torch.cuda.device_count())))\n",
    "\n",
    "#Optional orthogonal initialization of weights, does not work with Spectral Normalization!#########\n",
    "'''for m in netG.modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear, nn.ConvTranspose2d)):\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "\n",
    "for m in netD.modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear, nn.ConvTranspose2d)):\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "'''\n",
    "\n",
    "#Two Timescale Update Rule\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.0, 0.9))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = 0.0001, betas = (0.0, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "colab_type": "code",
    "id": "EAo3j9LQw0Hd",
    "outputId": "489113d7-eb44-44e4-a427-6eff4bf37fe6"
   },
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "disc_steps = 1\n",
    "batch_size = 16\n",
    "iterations = len(x_train)//batch_size\n",
    "path = \"./saved_models/\"\n",
    "\n",
    "for epoch in range(epochs + 1):\n",
    "    for i in range(iterations + 1):\n",
    "\n",
    "        #Dealing with the discriminator################################\n",
    "        netD.zero_grad()\n",
    "\n",
    "        next_batch = np.random.randint(0, len(x_train), size = batch_size)\n",
    "        data = torch.Tensor(x_train[next_batch])\n",
    "        thresh_data = torch.Tensor(y_train[next_batch]).to(device)\n",
    "\n",
    "        real_images = data.to(device)\n",
    "\n",
    "        real_images = torch.cat([real_images, thresh_data], dim = 1)\n",
    "        output = netD(real_images).view(-1)\n",
    "        errD_real = torch.mean(F.relu(1 - output))\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        noise = torch.randn(batch_size, noise_dim, device = device)\n",
    "        fake = netG(noise, thresh_data)\n",
    "\n",
    "        fake = torch.cat([fake, thresh_data], dim = 1)\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        errD_fake = torch.mean(F.relu(1 + output))\n",
    "        D_G_z1 = output.mean().item()\n",
    "\n",
    "        errD = errD_fake + errD_real\n",
    "        errD.backward()\n",
    "        optimizerD.step()\n",
    "            \n",
    "        #Dealing with the generator###################################\n",
    "        netG.zero_grad()\n",
    "\n",
    "        output = netD(fake).view(-1)\n",
    "        errG = -torch.mean(output)\n",
    "\n",
    "        D_G_z2 = output.mean().item()\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i%100 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                    % (epoch, epochs, i, len(x_train),\n",
    "                    errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "    \n",
    "    #if epoch%100 == 0:\n",
    "        #torch.save(netG.state_dict(), path + \"gaugan_G.pth\")\n",
    "        #torch.save(netD.state_dict(), path + \"gaugan_D.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "D6MIx8pxyAIb",
    "outputId": "521361b6-20f2-4d6e-e66e-40c6f70f2d4d"
   },
   "outputs": [],
   "source": [
    "noise = torch.randn(20, noise_dim, device = device)\n",
    "next_batch = np.random.randint(0, len(x_train), size = 20)\n",
    "thresh_data = torch.Tensor(y_train[next_batch]).to(device)\n",
    "real_images = torch.Tensor(x_train[next_batch])\n",
    "\n",
    "with torch.no_grad():\n",
    "  fake = netG(noise, thresh_data).cpu()\n",
    "\n",
    "print(\"Actual\")\n",
    "grid = torchvision.utils.make_grid(real_images, nrow = 5, padding = 1, pad_value = 0.15)\n",
    "f = plt.figure(figsize=(15,15))\n",
    "plt.imshow((grid.permute(1, 2, 0)+1)/2)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Binarized\")\n",
    "grid = torchvision.utils.make_grid(thresh_data.cpu(), nrow = 5, padding = 1, pad_value = 0.15)\n",
    "f = plt.figure(figsize=(15,15))\n",
    "plt.imshow((grid.permute(1, 2, 0)+1)/2)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"Noise produced\")\n",
    "grid = torchvision.utils.make_grid(fake, nrow = 5, padding = 1, pad_value = 0.15)\n",
    "f = plt.figure(figsize=(15,15))\n",
    "plt.imshow((grid.permute(1, 2, 0)+1)/2)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQsq78D856iU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GauGAN_BinThresh.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
