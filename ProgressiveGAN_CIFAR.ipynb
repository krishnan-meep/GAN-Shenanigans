{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progressive GAN\n",
    "\n",
    "Progressively growing a basic DCGAN using Wasserstein Loss with Gradient Penalty.\n",
    "The generator and discriminator are mirrored and grow in order of increasing resolution. So you train it on 8x8 resized images first, then 16x16 then 32x32 and so forth til you're at the resolution you're happy with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import grad as torch_grad\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from models.progressive import Prog_Generator, Prog_Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64\n",
    "\n",
    "def get_indices(dataset,class_name):\n",
    "    indices =  []\n",
    "    for i in range(len(dataset.targets)):\n",
    "        if dataset.targets[i] == class_name:\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "idx = get_indices(trainset, 5)\n",
    "\n",
    "#Use the first one if you only want to produce a particular class\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, num_workers=2, sampler = torch.utils.data.sampler.SubsetRandomSampler(idx))\n",
    "#trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, num_workers=2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = iter(trainloader)\n",
    "(data, target) = next(data_loader)\n",
    "\n",
    "print(data.shape)\n",
    "print(data.max(), data.min())\n",
    "img = np.transpose(data[0], (1, 2, 0))\n",
    "plt.imshow((img+1)/2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: This gradient penalty code is the same as the one in building_blocks.py, but I had to include two new parameters so I just put it here instead of modifying that one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradientPenalty(discriminator_model, real_data, generated_data, gp_weight = 10, steps = 0, alpha_rgb = -1):\n",
    "    batch_size = real_data.size()[0]\n",
    "\n",
    "    # Calculate interpolation\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1)\n",
    "    alpha = alpha.expand_as(real_data)\n",
    "    if torch.cuda.is_available():\n",
    "        alpha = alpha.cuda()\n",
    "\n",
    "    interpolated = alpha * real_data + (1 - alpha) * generated_data\n",
    "    interpolated = Variable(interpolated, requires_grad=True)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        interpolated = interpolated.cuda()\n",
    "\n",
    "    # Calculate probability of interpolated examples\n",
    "    prob_interpolated = discriminator_model(interpolated, steps = steps, alpha = alpha_rgb)\n",
    "\n",
    "    # Calculate gradients of probabilities with respect to examples\n",
    "    gradients = torch_grad(outputs=prob_interpolated, inputs=interpolated,\n",
    "                           grad_outputs=torch.ones(prob_interpolated.size()).cuda() if torch.cuda.is_available() else torch.ones(\n",
    "                           prob_interpolated.size()),\n",
    "                           create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    # Gradients have shape (batch_size, num_channels, img_width, img_height),\n",
    "    # so flatten to easily take norm per example in batch\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "\n",
    "    # Derivatives of the gradient close to 0 can cause problems because of\n",
    "    # the square root, so manually calculate norm and add epsilon\n",
    "    gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
    "\n",
    "    # Return gradient penalty\n",
    "    return gp_weight * ((gradients_norm - 1) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "noise_dim = 128\n",
    "netG = Prog_Generator(noise_dim = noise_dim).to(device)\n",
    "netD = Prog_Discriminator().to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    netG = nn.DataParallel(netG, list(range(torch.cuda.device_count())))\n",
    "    netD = nn.DataParallel(netD, list(range(torch.cuda.device_count())))\n",
    "\n",
    "#Optional orthogonal initialization of weights, does not work with Spectral Normalization!#########\n",
    "for m in netG.modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear, nn.ConvTranspose2d)):\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "\n",
    "for m in netD.modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear, nn.ConvTranspose2d)):\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "\n",
    "\n",
    "#Two Timescale Update Rule\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = 0.001, betas = (0.0, 0.9))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = 0.001, betas = (0.0, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "max_steps = int(np.log2(data[0].shape[2]) - 2)   #Based on image size, 32 would mean 3 steps/resolution levels of growth\n",
    "increment_interval = epochs//max_steps\n",
    "disc_steps = 1\n",
    "path = \"./saved_models/\"\n",
    "\n",
    "steps = 1          #Trains just upto 8x8\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    if epoch%increment_interval == 0:\n",
    "        steps += 1\n",
    "        \n",
    "    for i, (data, target) in enumerate(trainloader):\n",
    "\n",
    "        #Dealing with the discriminator################################\n",
    "        #Specify number of disc updates above##############\n",
    "        for s in range(disc_steps):\n",
    "            alpha = min(1, (2/(epochs//max_steps)) * epochs%increment_interval)\n",
    "            \n",
    "            netD.zero_grad()\n",
    "        \n",
    "            real_images = data.to(device)\n",
    "            \n",
    "            #Resize images according to step level\n",
    "            if steps != max_steps:\n",
    "                scale_factor = 2 ** (max_steps - steps)\n",
    "                real_images = F.interpolate(real_images, scale_factor = 1/scale_factor, mode = \"bilinear\", \n",
    "                                            align_corners = False)\n",
    "            \n",
    "            b_size = real_images.size(0)\n",
    "        \n",
    "            output = netD(real_images, steps = steps, alpha = alpha).view(-1)\n",
    "            errD_real = -torch.mean(output)\n",
    "            errD_real.backward()\n",
    "            D_x = output.mean().item()\n",
    "\n",
    "            noise = torch.randn(b_size, noise_dim, device = device)\n",
    "            fake = netG(noise, steps = steps, alpha = alpha)\n",
    "\n",
    "            output = netD(fake.detach(), steps = steps, alpha = alpha).view(-1)\n",
    "            errD_fake = torch.mean(output)\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "\n",
    "            GP = GradientPenalty(netD, real_images, fake, gp_weight = 10, steps = steps, alpha_rgb = alpha)\n",
    "\n",
    "            errD = errD_fake + errD_real + GP\n",
    "            optimizerD.step()\n",
    "            \n",
    "        #Dealing with the generator###################################\n",
    "        netG.zero_grad()\n",
    "\n",
    "        output = netD(fake, steps = steps, alpha = alpha).view(-1)\n",
    "        errG = -torch.mean(output)\n",
    "\n",
    "        D_G_z2 = output.mean().item()\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i%100 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                    % (epoch, epochs, i, len(trainloader),\n",
    "                    errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "    \n",
    "    #if epoch%100 == 0:\n",
    "     #   torch.save(netG.state_dict(), path + \"proggan_cifar_G.pth\")\n",
    "     #   torch.save(netD.state_dict(), path + \"proggan_cifar_D.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, a = plt.subplots(4, 8, figsize=(30, 8))\n",
    "for i in range(8):\n",
    "  noise = torch.randn(4, noise_dim, device = device)\n",
    "  with torch.no_grad():\n",
    "    fake = netG(noise, steps = max_steps)\n",
    "\n",
    "  for j in range(4):\n",
    "      img = fake[j].cpu()\n",
    "      img = np.transpose(img, (1, 2, 0))\n",
    "      img = (img+1)/2\n",
    "      a[j][i].imshow(img)\n",
    "      a[j][i].axis(\"off\")\n",
    "    \n",
    "plt.savefig(\"CIFCol.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
