{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SNGAN with Fractal Blocks, Spectral Normalization and Self Modulation\n",
    "\n",
    "SpecNorm in the Discriminator, Self Modulation with BatchNorm in the Generator, Wasserstein Loss with Gradient Penalty.\n",
    "Discriminator and Generators have Fractal Blocks in them, check /models. The level argument determines how deep the fractal block is, 0 being the default fractal block.\n",
    "\n",
    "The hyperparameters are from the WGAN-GP paper except for the number of disc_steps, which you can decrease with the inclusion of spectral normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from models.fractalnet import FractalNet_Generator, FractalNet_Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64\n",
    "\n",
    "def get_indices(dataset,class_name):\n",
    "    indices =  []\n",
    "    for i in range(len(dataset.targets)):\n",
    "        if dataset.targets[i] == class_name:\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "idx = get_indices(trainset, 2)\n",
    "\n",
    "#Use the first one if you only want to produce a particular class\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, num_workers=2, sampler = torch.utils.data.sampler.SubsetRandomSampler(idx))\n",
    "#trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, num_workers=2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = iter(trainloader)\n",
    "(data, target) = next(data_loader)\n",
    "\n",
    "print(data.shape)\n",
    "print(data.max(), data.min())\n",
    "img = np.transpose(data[0], (1, 2, 0))\n",
    "plt.imshow((img+1)/2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "noise_dim = 128\n",
    "netG = FractalNet_Generator(image_size = (32,32), level = 1, noise_dim = noise_dim).to(device)\n",
    "netD = FractalNet_Discriminator(image_size = (32,32), level = 1, mbd_features = None).to(device)\n",
    "\n",
    "print(netG)\n",
    "print(\"******************************************************************************************************************\")\n",
    "print(netD)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    netG = nn.DataParallel(netG, list(range(torch.cuda.device_count())))\n",
    "    netD = nn.DataParallel(netD, list(range(torch.cuda.device_count())))\n",
    "\n",
    "#Optional orthogonal initialization of weights, does not work with Spectral Normalization!#########\n",
    "for m in netG.modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear, nn.ConvTranspose2d)):\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "'''\n",
    "for m in netD.modules():\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear, nn.ConvTranspose2d)):\n",
    "        nn.init.orthogonal_(m.weight)\n",
    "'''\n",
    "\n",
    "#Two Timescale Update Rule\n",
    "optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.0, 0.9))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr = 0.0001, betas = (0.0, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "disc_steps = 1\n",
    "path = \"./saved_models/\"\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (data, target) in enumerate(trainloader):\n",
    "\n",
    "        #Dealing with the discriminator################################\n",
    "        #Specify number of disc updates above##############\n",
    "        for s in range(disc_steps):\n",
    "            netD.zero_grad()\n",
    "        \n",
    "            real_images = data.to(device)\n",
    "            b_size = real_images.size(0)\n",
    "        \n",
    "            output = netD(real_images).view(-1)\n",
    "            errD_real = -torch.mean(output)\n",
    "            errD_real.backward()\n",
    "            D_x = output.mean().item()\n",
    "\n",
    "            noise = torch.randn(b_size, noise_dim, device = device)\n",
    "            fake = netG(noise)\n",
    "\n",
    "            output = netD(fake.detach()).view(-1)\n",
    "            errD_fake = torch.mean(output)\n",
    "            errD_fake.backward()\n",
    "            D_G_z1 = output.mean().item()\n",
    "\n",
    "            GP = GradientPenalty(netD, real_images, fake, gp_weight = 10)\n",
    "            GP.backward()\n",
    "\n",
    "            errD = errD_fake + errD_real + GP\n",
    "            optimizerD.step()\n",
    "            \n",
    "        #Dealing with the generator###################################\n",
    "        netG.zero_grad()\n",
    "\n",
    "        output = netD(fake).view(-1)\n",
    "        errG = -torch.mean(output)\n",
    "\n",
    "        D_G_z2 = output.mean().item()\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i%100 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                    % (epoch, epochs, i, len(trainloader),\n",
    "                    errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "    \n",
    "    #if epoch%100 == 0:\n",
    "        #torch.save(netG.state_dict(), path + \"sngan_res_cifar_G.pth\")\n",
    "        #torch.save(netD.state_dict(), path + \"sngan_res_cifar_D.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, a = plt.subplots(4, 8, figsize=(20, 20))\n",
    "for i in range(8):\n",
    "  noise = torch.randn(4, noise_dim, device = device)\n",
    "  with torch.no_grad():\n",
    "    fake = netG(noise)\n",
    "\n",
    "  for j in range(4):\n",
    "      img = fake[j].cpu()\n",
    "      img = np.transpose(img, (1, 2, 0))\n",
    "      img = (img+1)/2\n",
    "      a[j][i].imshow(img)\n",
    "      a[j][i].axis(\"off\")\n",
    "    \n",
    "plt.savefig(\"CIFCol.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
